{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Experiment: toxic comments data\n",
    "\n",
    "## A. Import modules \n",
    "## B. Import functions \n",
    "## C. Load  data\n",
    "## D. Generate embeddings\n",
    "### 1) SVD\n",
    "### 2) word2vec\n",
    "### 3) Poincare\n",
    "## E. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import time\n",
    "import gensim\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from math import log, isnan\n",
    "import random\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from gensim.models import word2vec\n",
    "try:\n",
    "    maketrans = ''.maketrans\n",
    "except AttributeError:\n",
    "    # fallback for Python 2\n",
    "    from string import maketrans\n",
    "    \n",
    "import nltk\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transformation(input_text):\n",
    "    stemmer = LancasterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    \n",
    "    result = input_text.lower().replace('\\n',' ').translate(maketrans(\"\",\"\", string.punctuation)).strip().split(\" \")\n",
    "    \n",
    "    result = [stemmer.stem(str(i)) for i in result if not i in stop_words]\n",
    "    return result\n",
    "\n",
    "def generate_svd(transactions_dict, n_dim = 300, negative = False):\n",
    "\tdata_list = [v for _,v in transactions_dict.items()]\n",
    "\n",
    "\tunigrams_cnt = Counter()\n",
    "\tbigrams_cnt = Counter()\n",
    "\tfor text in data_list:\n",
    "\t\tfor x in text:\n",
    "\t\t\tunigrams_cnt[x] += 1\n",
    "\t\tfor x, y in map(sorted, combinations(text, 2)):\n",
    "\t\t\tbigrams_cnt[(x, y)] += 1\n",
    "\n",
    "\tid2uni = {}\n",
    "\tuni2id = {}\n",
    "\tit = 0\n",
    "\n",
    "\tfor uni,_ in unigrams_cnt.items():\n",
    "\t\tid2uni[it] = uni\n",
    "\t\tuni2id[uni] = it\n",
    "\t\tit +=1\n",
    "\n",
    "\n",
    "\tsum_uni = float(sum(unigrams_cnt.values()))\n",
    "\tsum_bi = float(sum(bigrams_cnt.values()))\n",
    "\n",
    "\tdata, rows, cols = [], [], []\n",
    "\tfor (x, y), n in bigrams_cnt.items():\n",
    "\t\trows.append(uni2id[x])\n",
    "\t\tcols.append(uni2id[y])\n",
    "\t\tdata.append(log((n / sum_bi) / (unigrams_cnt[x] / sum_uni) / (unigrams_cnt[y] / sum_uni)))\n",
    "\tPMI = csc_matrix((data, (cols, rows)), shape = (len(unigrams_cnt), len(unigrams_cnt)))\n",
    "\tU,_,_ = svds(PMI, k = n_dim)\n",
    "\tnorms = np.sqrt(np.sum(np.square(U), axis=1, keepdims=True))\n",
    "\tU /= np.maximum(norms, 1e-7)\n",
    "    \n",
    "    \n",
    "\n",
    "\tresult_t_dict = {}\n",
    "\n",
    "\tfor key in transactions_dict.keys():\n",
    "\t\tfor product in transactions_dict[key]:\n",
    "\t\t\ttemp = [U[uni2id[product]] for product in transactions_dict[key]]\n",
    "\t\t\tresult_t_dict[key] = power_means([x for x in temp])\n",
    "\n",
    "   \n",
    "\treturn result_t_dict\n",
    "\n",
    "def generate_word2vec(transactions_dict, n_dim = 300, n_workers = 10, n_epochs = 20, negative = False):\n",
    "\tdata_list = [v for _,v in transactions_dict.items()]\n",
    "\twindow_size = max([len(x) for x in data_list])\n",
    "\n",
    "\tmodel = word2vec.Word2Vec(data_list, size = n_dim, window = window_size, min_count = 1, workers = n_workers)\n",
    "\n",
    "\tmodel.train(data_list, total_examples = len(data_list), epochs = n_epochs)\n",
    "\n",
    "    \n",
    "\tresult_t_dict = {}\n",
    "\tresult_p_dict = {}\n",
    "\n",
    "\tfor key in transactions_dict.keys():\n",
    "\t\tresult_t_dict[key] = power_means([model[product] for product in transactions_dict[key]])\n",
    "\n",
    "\treturn result_t_dict\n",
    "\n",
    "def power_means(list_of_vectors, p = 1):\n",
    "\tdata = np.array(list_of_vectors)\n",
    "\n",
    "\treturn np.power(np.power(data,p).mean(axis=0), 1/p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('toxic_comments.csv', nrows = 10000)\n",
    "dataset['text'] = dataset.apply(lambda x: text_transformation(x['comment_text']), axis = 1)\n",
    "\n",
    "data_dict = {}\n",
    "score_dict = {}\n",
    "\n",
    "for i,row in dataset.iterrows():\n",
    "    data_dict[row['id']] = row['text']\n",
    "    score_dict[row['id']] = row['toxic']\n",
    "\n",
    "    \n",
    "keys = list(data_dict.keys())\n",
    "for key in keys:\n",
    "    if data_dict[key] == []:\n",
    "        data_dict.pop(key)\n",
    "        score_dict.pop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_dim = 100\n",
    "\n",
    "svd_embeddings = generate_svd(data_dict, n_dim = svd_dim)\n",
    "\n",
    "X_svd = [svd_embeddings[key] for key in score_dict.keys()]\n",
    "Y_svd = [score_dict[key] for key in score_dict.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "word2vec_dim = 20\n",
    "\n",
    "word2vec_embeddings = generate_word2vec(data_dict, n_dim = word2vec_dim)\n",
    "\n",
    "X_word2vec = [word2vec_embeddings[key] for key in score_dict.keys()]\n",
    "Y_word2vec = [score_dict[key] for key in score_dict.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_dataset = pd.read_csv(\"text_data_poincare_A_10k_50d.tsv\", sep=\"\\t\",header=None)\n",
    "\n",
    "poincare_rels_dict = {}\n",
    "poincare_dim = 50\n",
    "\n",
    "for _,row in poincare_dataset.iterrows():\n",
    "    poincare_rels_dict[row[0]] = [row[x] for x in range(1,poincare_dim+1)]\n",
    "\n",
    "diff_key = list(set([obj for key in data_dict.keys() for obj in data_dict[key]])-set([key for key in poincare_rels_dict.keys()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:77: RuntimeWarning: Mean of empty slice.\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "  \n",
    "poincare_embeddings = {}\n",
    "for key in data_dict.keys():\n",
    "    if key != '':\n",
    "        poincare_embeddings[key] = power_means([poincare_rels_dict[obj] for obj in data_dict[key] if obj not in diff_key])\n",
    "    \n",
    "    if poincare_embeddings[key] == []:\n",
    "        poincare_embeddings.pop(key)\n",
    "        score_dict.pop(key)\n",
    "    if str(poincare_embeddings[key]) == 'nan':\n",
    "        poincare_embeddings.pop(key)\n",
    "        if key in score_dict.keys():\n",
    "            score_dict.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poincare = [poincare_embeddings[key] for key in score_dict.keys()]\n",
    "Y_poincare = [score_dict[key] for key in score_dict.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,Y_svd_train,Y_svd_test = train_test_split(X_svd,Y_svd,test_size=0.3,stratify=Y_svd,random_state=111)\n",
    "\n",
    "d_clf = DummyClassifier(strategy='prior', random_state=0).fit([0 for i in range(len(Y_svd_train))],Y_svd_train)\n",
    "\n",
    "scoretrain = d_clf.score([1 for i in range(len(Y_svd_train))],Y_svd_train)\n",
    "scoretest  = d_clf.score([0 for i in range(len(Y_svd_test))],Y_svd_test)\n",
    "\n",
    "# print(\"Dummy classifier training score :{:2f} , Test Score: {:2f} \\n\".format(scoretrain,scoretest))\n",
    "\n",
    "results.append({\"method\":\"dummy\", \"test_score\":scoretest, \"train_score\":scoretrain,\"dim\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_svd_train,X_svd_test,Y_svd_train,Y_svd_test = train_test_split(X_svd,Y_svd,test_size=0.3,stratify=Y_svd,random_state=111)\n",
    "\n",
    "SVC_svd = SVC(kernel='linear').fit(X_svd_train,Y_svd_train)\n",
    "\n",
    "scoretrain = SVC_svd.score(X_svd_train,Y_svd_train)\n",
    "scoretest  = SVC_svd.score(X_svd_test,Y_svd_test)\n",
    "\n",
    "# print(\"Linear SVM training score :{:2f} , Test Score: {:2f} \\n\".format(scoretrain,scoretest))on\n",
    "\n",
    "results.append({\"method\":\"svd\", \"test_score\":scoretest, \"train_score\":scoretrain,\"dim\":svd_dim})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_word2vec_train,X_word2vec_test,Y_word2vec_train,Y_word2vec_test = train_test_split(X_word2vec,Y_word2vec,test_size=0.3,stratify=Y_word2vec,random_state=111)\n",
    "\n",
    "\n",
    "SVC_word2vec = SVC(kernel='linear').fit(X_word2vec_train,Y_word2vec_train)\n",
    "\n",
    "scoretrain = SVC_word2vec.score(X_word2vec_train,Y_word2vec_train)\n",
    "scoretest  = SVC_word2vec.score(X_word2vec_test,Y_word2vec_test)\n",
    "\n",
    "# print(\"Linear SVM training score :{:2f} , Test Score: {:2f} \\n\".format(scoretrain,scoretest))\n",
    "\n",
    "results.append({\"method\":\"word2vec\", \"test_score\":scoretest, \"train_score\":scoretrain,\"dim\":word2vec_dim})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poincare_train,X_poincare_test,Y_poincare_train,Y_poincare_test = train_test_split(X_poincare,Y_poincare,test_size=0.3,stratify=Y_poincare,random_state=111)\n",
    "\n",
    "\n",
    "SVC_poincare = SVC(kernel='linear').fit(X_poincare_train,Y_poincare_train)\n",
    "\n",
    "scoretrain = SVC_poincare.score(X_poincare_train,Y_poincare_train)\n",
    "scoretest  = SVC_poincare.score(X_poincare_test,Y_poincare_test)\n",
    "\n",
    "\n",
    "# print(\"Linear SVM training score :{:2f} , Test Score: {:2f} \\n\".format(scoretrain,scoretest))\n",
    "\n",
    "results.append({\"method\":\"poincare\", \"test_score\":scoretest, \"train_score\":scoretrain,\"dim\":poincare_dim})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim</th>\n",
       "      <th>method</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.924667</td>\n",
       "      <td>0.920703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>poincare</td>\n",
       "      <td>0.922333</td>\n",
       "      <td>0.918834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.903000</td>\n",
       "      <td>0.902829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.922667</td>\n",
       "      <td>0.920120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>0.930409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>svd</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.926836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.935333</td>\n",
       "      <td>0.936839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.929000</td>\n",
       "      <td>0.926122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>poincare</td>\n",
       "      <td>0.921333</td>\n",
       "      <td>0.918691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>poincare</td>\n",
       "      <td>0.916333</td>\n",
       "      <td>0.911117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>50</td>\n",
       "      <td>poincare</td>\n",
       "      <td>0.920667</td>\n",
       "      <td>0.915690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dim    method  test_score  train_score\n",
       "0     0     dummy    0.903000     0.902843\n",
       "1    10       svd    0.903000     0.902843\n",
       "2    10  word2vec    0.924667     0.920703\n",
       "3    10  poincare    0.922333     0.918834\n",
       "4     0     dummy    0.903000     0.902843\n",
       "5     0     dummy    0.903000     0.902843\n",
       "6     0     dummy    0.903000     0.902843\n",
       "7     0     dummy    0.903000     0.902843\n",
       "8     0     dummy    0.903000     0.902843\n",
       "9     0     dummy    0.903000     0.902843\n",
       "10    0     dummy    0.903000     0.902843\n",
       "11   10       svd    0.903000     0.902843\n",
       "12   10       svd    0.903000     0.902843\n",
       "13   20       svd    0.903000     0.902829\n",
       "14   50       svd    0.922667     0.920120\n",
       "15   50  word2vec    0.933000     0.930409\n",
       "16  100       svd    0.930000     0.926836\n",
       "17  100  word2vec    0.935333     0.936839\n",
       "18   20  word2vec    0.929000     0.926122\n",
       "19  100  poincare    0.921333     0.918691\n",
       "20   20  poincare    0.916333     0.911117\n",
       "21   50  poincare    0.920667     0.915690"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('experiment2_results.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
