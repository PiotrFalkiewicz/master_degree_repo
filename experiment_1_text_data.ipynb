{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Experiment: toxic comments data\n",
    "\n",
    "## A. Import modules and functions\n",
    "## B. Load & prepare data\n",
    "## C. Load test data\n",
    "## D. Experiment:a\n",
    "### 1) SVD\n",
    "### 2) word2vec\n",
    "### 3) Bitmap\n",
    "### 4) Poincare\n",
    "## E. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libs\n",
    "import numpy as np\n",
    "import time\n",
    "import gensim\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from math import log, isnan\n",
    "import random\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "try:\n",
    "    maketrans = ''.maketrans\n",
    "except AttributeError:\n",
    "    # fallback for Python 2\n",
    "    from string import maketrans\n",
    "    \n",
    "import nltk\n",
    "\n",
    "\n",
    "# import functions\n",
    "\n",
    "from search_algorithm import cosine_distance, a_nn, calc_cutoff, power_means, generate_transactions, generate_patterns\n",
    "from embeddings_script import generate_svd, generate_word2vec, generate_poincare, prepare_poincare_relations, prepare_poincare_relationsA, prepare_poincare_relationsB\n",
    "from bitmap_index import gen_index, search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_transformation(input_text):\n",
    "    stemmer = LancasterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    \n",
    "    result = input_text.lower().replace('\\n',' ').translate(maketrans(\"\",\"\", string.punctuation)).strip().split(\" \")\n",
    "    \n",
    "    result = [stemmer.stem(str(i)) for i in result if not i in stop_words]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('toxic_comments.csv', nrows = 5000)\n",
    "dataset['text'] = dataset.apply(lambda x: text_transformation(x['comment_text']), axis = 1)\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "for i,row in dataset.iterrows():\n",
    "    data_dict[row['id']] = row['text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Generate test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing took 0.20299744606018066 s\n"
     ]
    }
   ],
   "source": [
    "a_time = time.time()\n",
    "\n",
    "patterns_dict = {}\n",
    "i = 0\n",
    "for key in data_dict.keys():\n",
    "    patterns_dict['p_'+str(i)] = data_dict[key][:1]\n",
    "    i+=1\n",
    "    if len(data_dict[key]) > 2:\n",
    "        patterns_dict['p_'+str(i)] = data_dict[key][:2]\n",
    "        i+=1\n",
    "    if len(data_dict[key]) >3:\n",
    "        patterns_dict['p_'+str(i)] = data_dict[key][:len(data_dict[key])-2]\n",
    "        i+=1\n",
    "\n",
    "for key in patterns_dict.keys():\n",
    "    if str(patterns_dict[key]) == 'nan':\n",
    "        patterns_dict.pop(key)\n",
    "\n",
    "\n",
    "# for key in data_dict.keys():\n",
    "#     if str(data_dict[key]) == 'nan':\n",
    "#         data_dict.pop(key)\n",
    "        \n",
    "        \n",
    "        \n",
    "patterns_1 = [key for key in patterns_dict.keys() if len(patterns_dict[key]) == 1]\n",
    "patterns_2 = [key for key in patterns_dict.keys() if len(patterns_dict[key]) == 2]\n",
    "patterns_3 = [key for key in patterns_dict.keys() if len(patterns_dict[key]) > 2]\n",
    "\n",
    "experimental_data = patterns_dict\n",
    "experimental_data.update(data_dict)\n",
    "\n",
    "\n",
    "to_delete = []\n",
    "for key in experimental_data.keys():\n",
    "    if experimental_data[key] == []:\n",
    "        to_delete.append(key)\n",
    "        \n",
    "for key in to_delete:\n",
    "    experimental_data.pop(key)\n",
    "\n",
    "print(\"Processing took {} s\".format(time.time()-a_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3016855185060599\n",
      "Processing took 820.5123383998871 s\n"
     ]
    }
   ],
   "source": [
    "a_time = time.time()\n",
    "\n",
    "svd = generate_svd(experimental_data, n_dim = 300)\n",
    "\n",
    "p_data = {}\n",
    "p_svd = {}\n",
    "t_data = {}\n",
    "t_svd = {}\n",
    "\n",
    "for key in svd.keys():\n",
    "    if str(key)[0] == 'p':\n",
    "        p_svd[key] = svd[key]\n",
    "        p_data[key] = experimental_data[key]\n",
    "    else:\n",
    "        t_svd[key] = svd[key]\n",
    "        t_data[key] = experimental_data[key]\n",
    "\n",
    "svd_cutoff = calc_cutoff(p_data,p_svd,t_data,t_svd)\n",
    "\n",
    "print(svd_cutoff)\n",
    "\n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching quality: 0.7632149046793761\n",
      "Processing took 3478.0479485988617 s\n"
     ]
    }
   ],
   "source": [
    "test_patterns1 = patterns_1[:5000] #75%/10k;59%/10k\n",
    "test_patterns2 = patterns_2[:len(test_patterns1)] #65%/10k;23%/10k\n",
    "test_patterns3 = patterns_3[:len(test_patterns1)] #86%/10k;43%/10k\n",
    "\n",
    "# test_patterns = test_patterns1\n",
    "\n",
    "# a_time = time.time()\n",
    "\n",
    "# length = 0\n",
    "# correct = 0\n",
    "# for pattern in test_patterns:\n",
    "#     for transaction in t_svd.keys():\n",
    "#         if cosine_distance(p_svd[pattern],t_svd[transaction]) < svd_cutoff:\n",
    "#             if set(p_data[pattern]) <= set(t_data[transaction]):\n",
    "#                 correct += 1\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#     length += 1\n",
    "\n",
    "# print(\"Searching quality: {}\".format(float(correct)/float(length)))            \n",
    "# print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "# test_patterns = test_patterns2\n",
    "\n",
    "# a_time = time.time()\n",
    "\n",
    "# length = 0\n",
    "# correct = 0\n",
    "# for pattern in test_patterns:\n",
    "#     for transaction in t_svd.keys():\n",
    "#         if cosine_distance(p_svd[pattern],t_svd[transaction]) < svd_cutoff:\n",
    "#             if set(p_data[pattern]) <= set(t_data[transaction]):\n",
    "#                 correct += 1\n",
    "            \n",
    "#             break\n",
    "            \n",
    "#     length += 1\n",
    "\n",
    "# print(\"Searching quality: {}\".format(float(correct)/float(length)))            \n",
    "# print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "test_patterns = test_patterns3\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "length = 0\n",
    "correct = 0\n",
    "for pattern in test_patterns:\n",
    "    for transaction in t_svd.keys():\n",
    "        if cosine_distance(p_svd[pattern],t_svd[transaction]) < svd_cutoff:\n",
    "            if set(p_data[pattern]) <= set(t_data[transaction]):\n",
    "                correct += 1\n",
    "            \n",
    "            break\n",
    "            \n",
    "    length += 1\n",
    "\n",
    "print(\"Searching quality: {}\".format(float(correct)/float(length)))            \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "# Searching quality: 0.6741348269653931\n",
    "# Processing took 3329.4174551963806 s\n",
    "# Searching quality: 0.2996599319863973\n",
    "# Processing took 3166.5946822166443 s\n",
    "# Searching quality: 0.7632149046793761\n",
    "# Processing took 3478.0479485988617 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generation took 90.14730715751648 s\n",
      "0.5203972983027424\n",
      "Processing took 93.18852305412292 s\n"
     ]
    }
   ],
   "source": [
    "a_time = time.time()\n",
    "\n",
    "\n",
    "word2vec = generate_word2vec(experimental_data)\n",
    "\n",
    "print(\"Model generation took {} s\".format(time.time()-a_time))\n",
    "\n",
    "p_data = {}\n",
    "p_word2vec = {}\n",
    "t_data = {}\n",
    "t_word2vec = {}\n",
    "\n",
    "for key in word2vec.keys():\n",
    "    if str(key)[0] == 'p':\n",
    "        p_word2vec[key] = word2vec[key]\n",
    "        p_data[key] = experimental_data[key]\n",
    "    else:\n",
    "        t_word2vec[key] = word2vec[key]\n",
    "        t_data[key] = experimental_data[key]\n",
    "\n",
    "word2vec_cutoff = calc_cutoff(p_data,p_word2vec,t_data,t_word2vec)\n",
    "\n",
    "print(word2vec_cutoff)\n",
    "\n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "# Last run time:\n",
    "# 5 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5319072774727861\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word2vec_cutoff = calc_cutoff(p_data,p_word2vec,t_data,t_word2vec)\n",
    "\n",
    "print(word2vec_cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching quality: 0.904968644476604\n",
      "Empty runs: 1707.0 Correct: 7504.0 TOTAL: 9999.0 ratio correct/total: 0.7504750475047505\n",
      "Processing took 377.24962401390076 s\n",
      "Searching quality: 0.15081508150815082\n",
      "Empty runs: 0.0 Correct: 1508.0 TOTAL: 9999.0 ratio correct/total: 0.15081508150815082\n",
      "Processing took 229.97160744667053 s\n",
      "Searching quality: 0.0560302866414278\n",
      "Empty runs: 0.0 Correct: 518.0 TOTAL: 9245.0 ratio correct/total: 0.0560302866414278\n",
      "Processing took 43.96140766143799 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "test_patterns1 = patterns_1[:10000] #75%/10k;59%/10k\n",
    "test_patterns2 = patterns_2[:len(test_patterns1)] #65%/10k;23%/10k\n",
    "test_patterns3 = patterns_3[:len(test_patterns1)] #86%/10k;43%/10k\n",
    "\n",
    "test_patterns = test_patterns1\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "length = 0\n",
    "correct = 0\n",
    "empty_run = 0\n",
    "for pattern in test_patterns:\n",
    "    found = False\n",
    "    for transaction in t_word2vec.keys():\n",
    "        if cosine_distance(p_word2vec[pattern],t_word2vec[transaction]) < word2vec_cutoff:\n",
    "            if set(p_data[pattern]) <= set(t_data[transaction]):\n",
    "                correct += 1\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        empty_run+=1\n",
    "    length += 1\n",
    "\n",
    "print(\"Searching quality: {}\".format(float(correct)/(float(length)-float(empty_run))))\n",
    "print(\"Empty runs: {} Correct: {} TOTAL: {} ratio correct/total: {}\".format(float(empty_run),float(correct),float(length),float(correct)/float(length)))            \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "test_patterns = test_patterns2\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "length = 0\n",
    "correct = 0\n",
    "empty_run = 0\n",
    "for pattern in test_patterns:\n",
    "    for transaction in t_word2vec.keys():\n",
    "        if cosine_distance(p_word2vec[pattern],t_word2vec[transaction]) < word2vec_cutoff:\n",
    "            if set(p_data[pattern]) <= set(t_data[transaction]):\n",
    "                correct += 1\n",
    "            found = True\n",
    "            break\n",
    "            \n",
    "    if not found:\n",
    "        empty_run+=1\n",
    "    length += 1\n",
    "\n",
    "print(\"Searching quality: {}\".format(float(correct)/(float(length)-float(empty_run))))\n",
    "print(\"Empty runs: {} Correct: {} TOTAL: {} ratio correct/total: {}\".format(float(empty_run),float(correct),float(length),float(correct)/float(length)))            \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "\n",
    "test_patterns = test_patterns3\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "length = 0\n",
    "correct = 0\n",
    "empty_run = 0\n",
    "for pattern in test_patterns:\n",
    "    for transaction in t_word2vec.keys():\n",
    "        if cosine_distance(p_word2vec[pattern],t_word2vec[transaction]) < word2vec_cutoff:\n",
    "            if set(p_data[pattern]) <= set(t_data[transaction]):\n",
    "                correct += 1\n",
    "            found = True\n",
    "            break\n",
    "            \n",
    "    if not found:\n",
    "        empty_run+=1\n",
    "                        \n",
    "    length += 1\n",
    "\n",
    "print(\"Searching quality: {}\".format(float(correct)/(float(length)-float(empty_run))))\n",
    "print(\"Empty runs: {} Correct: {} TOTAL: {} ratio correct/total: {}\".format(float(empty_run),float(correct),float(length),float(correct)/float(length)))              \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "# Searching quality: 0.921667628390075\n",
    "# Empty runs: 3067.0 Correct: 6389.0 TOTAL: 9999.0 ratio correct/total: 0.638963896389639\n",
    "# Processing took 525.1704280376434 s\n",
    "# Searching quality: 0.23445026178010472\n",
    "# Empty runs: 0.0 Correct: 2239.0 TOTAL: 9550.0 ratio correct/total: 0.23445026178010472\n",
    "# Processing took 430.62952637672424 s\n",
    "# Searching quality: 0.2741135180927024\n",
    "# Empty runs: 0.0 Correct: 2265.0 TOTAL: 8263.0 ratio correct/total: 0.2741135180927024\n",
    "# Processing took 186.3489751815796 s\n",
    "\n",
    "# Searching quality: 0.9070177648985763\n",
    "# Empty runs: 2062.0 Correct: 7199.0 TOTAL: 9999.0 ratio correct/total: 0.7199719971997199\n",
    "# Processing took 417.22366738319397 s\n",
    "# Searching quality: 0.14607329842931938\n",
    "# Empty runs: 0.0 Correct: 1395.0 TOTAL: 9550.0 ratio correct/total: 0.14607329842931938\n",
    "# Processing took 223.90713953971863 s\n",
    "# Searching quality: 0.09972165073217959\n",
    "# Empty runs: 0.0 Correct: 824.0 TOTAL: 8263.0 ratio correct/total: 0.09972165073217959\n",
    "# Processing took 72.7106556892395 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Bitmap index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_time = time.time()\n",
    "\n",
    "t_index, i_index = gen_index(experimental_data, d = 64)\n",
    "\n",
    "print(\"Index generated\")\n",
    "\n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "# Last run time:\n",
    "# 80 s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_time = time.time()\n",
    "\n",
    "\n",
    "test_dict = {}\n",
    "test_i = {}\n",
    "pattern_dict = {}\n",
    "pattern_i = {}\n",
    "\n",
    "# test_keys = [key for key in data_dict.keys() if str(key)[0] == 't']\n",
    "\n",
    "for key in t_index.keys():\n",
    "    if str(key)[0] != 'p':\n",
    "        test_dict[key] = t_index[key]\n",
    "        test_i[key] = i_index[key]\n",
    "    elif str(key)[0] == 'p':\n",
    "        pattern_dict[key] = t_index[key]\n",
    "        pattern_i[key] = i_index[key]\n",
    "    \n",
    "\n",
    "print(\"Processing took {} s\".format(time.time() - a_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patterns1 = patterns_1[:10000] #75%/10k;59%/10k\n",
    "test_patterns2 = patterns_2[:len(test_patterns1)] #65%/10k;23%/10k\n",
    "test_patterns3 = patterns_3[:len(test_patterns1)] #86%/10k;43%/10k\n",
    "\n",
    "test_patterns = test_patterns1\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "count = 0\n",
    "correct = 0\n",
    "real_correct = 0\n",
    "for key in test_patterns:\n",
    "    for t_key in test_dict.keys():\n",
    "        trigger = False\n",
    "        if set(experimental_data[key]) <= set(experimental_data[t_key]):\n",
    "            trigger = True\n",
    "        if search(pattern_dict[key],pattern_i[key],test_dict[t_key],test_i[t_key]):\n",
    "            correct +=1\n",
    "            if trigger:\n",
    "                real_correct += 1\n",
    "            break\n",
    "    count+=1\n",
    "\n",
    "            \n",
    "print(\"Searching quality: {} {}\".format(float(correct)/float(count),float(real_correct)/float(count)))            \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "test_patterns = test_patterns2\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "\n",
    "count = 0\n",
    "correct = 0\n",
    "real_correct = 0\n",
    "for key in test_patterns:\n",
    "    for t_key in test_dict.keys():\n",
    "        trigger = False\n",
    "        if set(experimental_data[key]) <= set(experimental_data[t_key]):\n",
    "            trigger = True\n",
    "        if search(pattern_dict[key],pattern_i[key],test_dict[t_key],test_i[t_key]):\n",
    "            correct +=1\n",
    "            if trigger:\n",
    "                real_correct += 1\n",
    "            break\n",
    "    count+=1\n",
    "\n",
    "            \n",
    "print(\"Searching quality: {} {}\".format(float(correct)/float(count),float(real_correct)/float(count)))            \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "test_patterns = test_patterns3\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "\n",
    "count = 0\n",
    "correct = 0\n",
    "real_correct = 0\n",
    "for key in test_patterns:\n",
    "    for t_key in test_dict.keys():\n",
    "        trigger = False\n",
    "        if set(experimental_data[key]) <= set(experimental_data[t_key]):\n",
    "            trigger = True\n",
    "        if search(pattern_dict[key],pattern_i[key],test_dict[t_key],test_i[t_key]):\n",
    "            correct +=1\n",
    "            if trigger:\n",
    "                real_correct += 1\n",
    "            break\n",
    "    count+=1\n",
    "\n",
    "            \n",
    "print(\"Searching quality: {} {}\".format(float(correct)/float(count),float(real_correct)/float(count)))            \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "# Searching quality: 1.0 1.0\n",
    "# Processing took 40.4065318107605 s\n",
    "# Searching quality: 1.0 1.0\n",
    "# Processing took 104.36041164398193 s\n",
    "# Searching quality: 1.0 1.0\n",
    "# Processing took 156.75257325172424 s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embeddings\n",
    "poincare_embeddings = pd.read_csv(\"text_data_poincare_A_full_10d.tsv\", sep=\"\\t\",header=None)\n",
    "\n",
    "poincare_rels_dict = {}\n",
    "\n",
    "for _,row in poincare_embeddings.iterrows():\n",
    "#     print(row[0])\n",
    "#     print([row[x] for x in range(1,11)])\n",
    "#     break\n",
    "    poincare_rels_dict[row[0]] = [row[x] for x in range(1,11)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196141, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poincare_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'nan', 'null']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_keys = list(set([key for key in poincare_rels_dict.keys()]))\n",
    "exp_keys = list(set([obj for key in experimental_data.keys() for obj in experimental_data[key]]))\n",
    "difference = list(set(exp_keys)-set(p_keys))\n",
    "difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  import sys\n",
      "/root/search_algorithm.py:149: RuntimeWarning: Mean of empty slice.\n",
      "  return np.power(np.power(data,p).mean(axis=0), 1/p)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4390734031031121\n",
      "Processing took 9.89581561088562 s\n"
     ]
    }
   ],
   "source": [
    "a_time = time.time()\n",
    "poincare = {}\n",
    "for key in experimental_data.keys():\n",
    "    if key != '':\n",
    "        poincare[key] = power_means([poincare_rels_dict[obj] for obj in experimental_data[key] if obj not in difference])\n",
    "    \n",
    "    if poincare[key] == []:\n",
    "        poincare.pop(key)\n",
    "    if str(poincare[key]) == 'nan':\n",
    "        poincare.pop(key)\n",
    "\n",
    "patterns_dict = {}\n",
    "poincare_patterns = {}\n",
    "t_data = {}\n",
    "poincare_transactions = {}\n",
    "\n",
    "for key in poincare.keys():\n",
    "    if str(key)[0] == 'p':\n",
    "        poincare_patterns[key] = poincare[key]\n",
    "        patterns_dict[key] = experimental_data[key]\n",
    "    else:\n",
    "        poincare_transactions[key] = poincare[key]\n",
    "        t_data[key] = experimental_data[key]\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "poincare_cutoff = calc_cutoff(patterns_dict,poincare_patterns,t_data,poincare_transactions)\n",
    "\n",
    "print(poincare_cutoff)\n",
    "\n",
    "print(\"Processing took {} s\".format(time.time()-a_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching quality: 0.0914\n",
      "Empty runs: 0.0 Correct: 457.0 TOTAL: 5000.0 ratio correct/total: 0.0914\n",
      "Processing took 1.212188959121704 s\n",
      "Searching quality: 0.014467631175411694\n",
      "Empty runs: 0.0 Correct: 217.0 TOTAL: 14999.0 ratio correct/total: 0.014467631175411694\n",
      "Processing took 2.1888270378112793 s\n",
      "Searching quality: 0.00013034410844629823\n",
      "Empty runs: 0.0 Correct: 2.0 TOTAL: 15344.0 ratio correct/total: 0.00013034410844629823\n",
      "Processing took 0.05595088005065918 s\n"
     ]
    }
   ],
   "source": [
    "test_patterns1 = [key for key in poincare_patterns.keys() if len(experimental_data[key]) == 1][:5000] #75%/10k;59%/10k\n",
    "test_patterns2 = [key for key in poincare_patterns.keys() if len(experimental_data[key]) == 2][:len(patterns_1)] #65%/10k;23%/10k\n",
    "test_patterns3 = [key for key in poincare_patterns.keys() if len(experimental_data[key]) == 3][:len(patterns_1)] #86%/10k;43%/10k\n",
    "\n",
    "test_patterns = test_patterns1\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "length = 0\n",
    "correct = 0\n",
    "empty_run = 0\n",
    "for pattern in test_patterns:\n",
    "    for transaction in poincare_transactions.keys():\n",
    "        found = False\n",
    "        if cosine_distance(poincare_patterns[pattern],poincare_transactions[transaction]) < poincare_cutoff:\n",
    "            if set(patterns_dict[pattern]) <= set(data_dict[transaction]):\n",
    "                correct += 1\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        empty_run+=1\n",
    "            \n",
    "    length += 1\n",
    "\n",
    "\n",
    "print(\"Searching quality: {}\".format(float(correct)/(float(length)-float(empty_run))))\n",
    "print(\"Empty runs: {} Correct: {} TOTAL: {} ratio correct/total: {}\".format(float(empty_run),float(correct),float(length),float(correct)/float(length)))              \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "test_patterns = test_patterns2\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "correct = 0\n",
    "empty_run = 0\n",
    "for pattern in test_patterns:\n",
    "    for transaction in poincare_transactions.keys():\n",
    "        found = False\n",
    "        if cosine_distance(poincare_patterns[pattern],poincare_transactions[transaction]) < poincare_cutoff:\n",
    "            if set(patterns_dict[pattern]) <= set(data_dict[transaction]):\n",
    "                correct += 1\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        empty_run+=1\n",
    "            \n",
    "    length += 1\n",
    "\n",
    "\n",
    "print(\"Searching quality: {}\".format(float(correct)/(float(length)-float(empty_run))))\n",
    "print(\"Empty runs: {} Correct: {} TOTAL: {} ratio correct/total: {}\".format(float(empty_run),float(correct),float(length),float(correct)/float(length)))              \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "test_patterns = test_patterns3\n",
    "\n",
    "a_time = time.time()\n",
    "\n",
    "correct = 0\n",
    "empty_run = 0\n",
    "for pattern in test_patterns:\n",
    "    for transaction in poincare_transactions.keys():\n",
    "        found = False\n",
    "        if cosine_distance(poincare_patterns[pattern],poincare_transactions[transaction]) < poincare_cutoff:\n",
    "            if set(patterns_dict[pattern]) <= set(data_dict[transaction]):\n",
    "                correct += 1\n",
    "            found = True\n",
    "            break\n",
    "    if not found:\n",
    "        empty_run+=1\n",
    "            \n",
    "    length += 1\n",
    "\n",
    "\n",
    "print(\"Searching quality: {}\".format(float(correct)/(float(length)-float(empty_run))))\n",
    "print(\"Empty runs: {} Correct: {} TOTAL: {} ratio correct/total: {}\".format(float(empty_run),float(correct),float(length),float(correct)/float(length)))              \n",
    "print(\"Processing took {} s\".format(time.time()-a_time))\n",
    "\n",
    "\n",
    "# C, d == 10\n",
    "# Searching quality: 0.0762\n",
    "# Processing took 0.2690761089324951 s\n",
    "# Searching quality: 0.013961072047284214\n",
    "# Processing took 0.4956812858581543 s\n",
    "# Searching quality: 0.005426275696545967\n",
    "# Processing took 0.4933924674987793 s\n",
    "\n",
    "# A, d == 10\n",
    "# Searching quality: 0.0914\n",
    "# Empty runs: 0.0 Correct: 457.0 TOTAL: 5000.0 ratio correct/total: 0.0914\n",
    "# Processing took 1.212188959121704 s\n",
    "# Searching quality: 0.014467631175411694\n",
    "# Empty runs: 0.0 Correct: 217.0 TOTAL: 14999.0 ratio correct/total: 0.014467631175411694\n",
    "# Processing took 2.1888270378112793 s\n",
    "# Searching quality: 0.00013034410844629823\n",
    "# Empty runs: 0.0 Correct: 2.0 TOTAL: 15344.0 ratio correct/total: 0.00013034410844629823\n",
    "# Processing took 0.05595088005065918 s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
